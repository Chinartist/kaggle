{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Libraries\n",
    "# =========================================================================================\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "import cupy as cp\n",
    "from cuml.metrics import pairwise_distances\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "# =========================================================================================\n",
    "# Data Loading\n",
    "# =========================================================================================\n",
    "import re\n",
    "import string\n",
    "\n",
    "def read_data(cfg):\n",
    "    content = pd.read_csv(\"/mnt/hdd1/wangjingqi/dataset/lecr/content.csv\")\n",
    "    topics = pd.read_csv(\"/mnt/hdd1/wangjingqi/dataset/lecr/topics.csv\")\n",
    "    correlations = pd.read_csv(\"/mnt/hdd1/wangjingqi/dataset/lecr/correlations.csv\")\n",
    "    \n",
    "    topics['title'].fillna(\"\", inplace = True)\n",
    "    content['title'].fillna(\"\", inplace = True)\n",
    "    topics['description'].fillna(\"\", inplace = True)\n",
    "    content['description'].fillna(\"\", inplace = True)\n",
    "    content['text'].fillna(\"\", inplace = True)\n",
    "\n",
    "    topics[\"Ti\"] = topics[\"title\"]\n",
    "    content[\"Ti\"] = content[\"title\"]\n",
    "    \n",
    "    topics[\"TiDe\"] = topics[\"title\"]+\" \"+topics[\"description\"]\n",
    "    content[\"TiDe\"] = content[\"title\"]+\" \"+content[\"description\"]\n",
    "\n",
    "    topics[\"TiDeTe\"] = topics[\"title\"]+\" \"+topics[\"description\"]\n",
    "    content[\"TiDeTe\"] = content[\"title\"]+\" \"+content[\"description\"]+\" \"+content[\"text\"]\n",
    "\n",
    "    topics['length'] = topics[cfg.uns_key].apply(lambda x: len(x))\n",
    "    content['length'] = content[cfg.uns_key].apply(lambda x: len(x))\n",
    "    \n",
    "    topics.sort_values('length', inplace = True)\n",
    "    content.sort_values('length', inplace = True)\n",
    "    # Drop cols\n",
    "    topics.drop(['title','description', 'channel', 'category', 'level', 'has_content', 'length'], axis = 1, inplace = True)\n",
    "    content.drop(['title','description', 'kind',  'text', 'copyright_holder', 'license', 'length'], axis = 1, inplace = True)\n",
    "    # Reset index\n",
    "    topics.reset_index(drop = True, inplace = True)\n",
    "    content.reset_index(drop = True, inplace = True)\n",
    "    print(' ')\n",
    "    print('-' * 50)\n",
    "    print(f\"topics.shape: {topics.shape}\")\n",
    "    print(f\"content.shape: {content.shape}\")\n",
    "    print(f\"correlations.shape: {correlations.shape}\")\n",
    "    return topics, content, correlations\n",
    "\n",
    "class LECRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df,key):\n",
    "        self.inputs = df[key].values\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    def __getitem__(self,idx):\n",
    "        sample = self.inputs[idx]\n",
    "        return sample\n",
    "\n",
    "class collator():\n",
    "    def __init__(self,pretrained_path,max_len=None) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_path)\n",
    "        self.max_len = max_len\n",
    "    def __call__(self, data):\n",
    "        inputs = self.tokenize(list(data))\n",
    "        return inputs\n",
    "    def tokenize(self,texts):\n",
    "            return self.tokenizer(\n",
    "                texts,padding='longest',max_length=self.max_len,truncation=True,return_tensors=\"pt\",return_token_type_ids=False)\n",
    "# =========================================================================================\n",
    "# Unsupervised model\n",
    "# =========================================================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    def forward(self,hidden_state, attention_mask):\n",
    "\n",
    "        input_mask_expanded = (\n",
    "            attention_mask.unsqueeze(-1).expand(hidden_state.size())\n",
    "        )\n",
    "        mean_embeddings = torch.sum(hidden_state * input_mask_expanded, 1) / torch.clamp(\n",
    "            input_mask_expanded.sum(1), min=1e-9)\n",
    "        return mean_embeddings\n",
    "\n",
    "class UNSModel(nn.Module):\n",
    "    def __init__(self, pretrained_path):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(pretrained_path)\n",
    "        self.pool = MeanPooling()\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        return feature\n",
    "    \n",
    "# =========================================================================================\n",
    "# Get embeddings\n",
    "# =========================================================================================\n",
    "def get_embeddings(loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for step, inputs in enumerate(tqdm(loader)):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds\n",
    "\n",
    "# =========================================================================================\n",
    "# Get the amount of positive classes based on the total\n",
    "# =========================================================================================\n",
    "def get_pos_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    int_true = np.array([len(x[0] & x[1]) / len(x[0]) for x in zip(y_true, y_pred)])\n",
    "    return round(np.mean(int_true), 5)\n",
    "\n",
    "# =========================================================================================\n",
    "# Build our training set\n",
    "# =========================================================================================\n",
    "def build_training_set(topics, content, cfg):\n",
    "    # Create lists for training\n",
    "   \n",
    "    input_key = cfg.sup_key\n",
    "    topics_ids = []\n",
    "    content_ids = []\n",
    "    input1 = []\n",
    "    input2 = []\n",
    "    targets = []\n",
    "    topics_languages = []\n",
    "    content_languages = []\n",
    "    # Iterate over each topic\n",
    "    for k in tqdm(range(len(topics))):\n",
    "        row = topics.iloc[k]\n",
    "        topics_id = row['id']\n",
    "        topics_input = row[input_key]\n",
    "        topics_language = row['language']\n",
    "        predictions = row['predictions'].split(' ')\n",
    "        ground_truth = row['content_ids'].split(' ')\n",
    "        predictions = list(set(predictions)|set(ground_truth))\n",
    "        for pred in predictions:\n",
    "            content_language = content.loc[pred, 'language']\n",
    "            content_input= content.loc[pred, input_key]\n",
    "            topics_ids.append(topics_id)\n",
    "            content_ids.append(pred)\n",
    "            input1.append(topics_input)\n",
    "            input2.append(content_input)\n",
    "            topics_languages.append(topics_language)\n",
    "            content_languages.append(content_language)\n",
    "            # If pred is in ground truth, 1 else 0\n",
    "            if pred in ground_truth:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "    # Build training dataset\n",
    "    train = pd.DataFrame(\n",
    "        {'topics_ids': topics_ids, \n",
    "         'content_ids': content_ids, \n",
    "         'input1': input1, \n",
    "         'input2': input2, \n",
    "         'target': targets,\n",
    "         'topic_language': topics_languages, \n",
    "         'content_language': content_languages, }\n",
    "    )\n",
    "    # Release memory\n",
    "    del topics_ids, content_ids, input1, input2, targets\n",
    "    gc.collect()\n",
    "    return train\n",
    "    \n",
    "# =========================================================================================\n",
    "# Get neighbors\n",
    "# =========================================================================================\n",
    "def get_neighbors(topics, content, cfg):\n",
    "    # Create topics dataset\n",
    "    topics_dataset = LECRDataset(topics,cfg.uns_key)\n",
    "    # Create content dataset\n",
    "    content_dataset = LECRDataset(content,cfg.uns_key)\n",
    "    \n",
    "    collate_fn= collator(cfg.model_name, cfg.max_len)\n",
    "    # Create topics and content dataloaders\n",
    "    topics_loader = DataLoader(topics_dataset,batch_size = cfg.bs, shuffle = False, num_workers= cfg.nw, pin_memory=True,collate_fn =collate_fn,drop_last=False)\n",
    "    content_loader = DataLoader(content_dataset,batch_size = cfg.bs, shuffle = False, num_workers= cfg.nw, pin_memory=True,collate_fn =collate_fn,drop_last=False)\n",
    "    # Create unsupervised model to extract embeddings\n",
    "    model = UNSModel(cfg.model_name)\n",
    "    model.to(cfg.device)\n",
    "    model.float()\n",
    "    # Predict topics\n",
    "    cp.cuda.Device(cfg.device).use()\n",
    "    print(torch.cuda.current_device())\n",
    "    topics_preds = get_embeddings(topics_loader, model, cfg.device)\n",
    "    topics_preds_gpu = cp.array(topics_preds)\n",
    "    del topics_loader\n",
    "    gc.collect()\n",
    "    content_preds = get_embeddings(content_loader, model, cfg.device)\n",
    "    # Transfer predictions to gpu\n",
    "    \n",
    "    content_preds_gpu = cp.array(content_preds)\n",
    "    # Release memory\n",
    "    torch.cuda.empty_cache()\n",
    "    del topics_dataset, content_dataset, content_loader, topics_preds, content_preds\n",
    "    gc.collect()\n",
    "    # KNN model\n",
    "    print(' ')\n",
    "    print('Training KNN model...')\n",
    "    neighbors_model = NearestNeighbors(n_neighbors = cfg.top_n, metric = 'cosine')\n",
    "    neighbors_model.fit(content_preds_gpu)\n",
    "    indices = neighbors_model.kneighbors(topics_preds_gpu, return_distance = False)\n",
    "    predictions = []\n",
    "    for k in range(len(indices)):\n",
    "        pred = indices[k]\n",
    "        p = ' '.join([content.loc[ind, 'id'] for ind in pred.get()])\n",
    "        predictions.append(p)\n",
    "    topics['predictions'] = predictions\n",
    "    # Release memory\n",
    "    del topics_preds_gpu, content_preds_gpu, neighbors_model, predictions, indices, model\n",
    "    gc.collect()\n",
    "    return topics, content \n",
    "\n",
    "# Read data\n",
    "# topics, content, correlations = read_data(CFG)\n",
    "# # Run nearest neighbors\n",
    "# topics, content = get_neighbors(topics, content, CFG)\n",
    "# # Merge with target and comput max positive score\n",
    "# topics = topics.merge(correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "# pos_score = get_pos_score(topics['content_ids'], topics['predictions'])\n",
    "# print(f'Our max positive score is {pos_score}')\n",
    "# # We can delete correlations\n",
    "# del correlations\n",
    "# gc.collect()\n",
    "# # Set id as index for content\n",
    "# content.set_index('id', inplace = True)\n",
    "# # Build training set\n",
    "# train = build_training_set(topics, content, CFG)\n",
    "# print(f'Our training set has {len(train)} rows')\n",
    "# # Save train set to disk to train on another notebook\n",
    "# train.to_csv('train.csv', index = False)\n",
    "# train.head()\n",
    "def test(CFG,models):\n",
    "    scores = {}\n",
    "    for model in models:\n",
    "        id = model.split('/')[-1]\n",
    "        CFG.model_name = model\n",
    "        print(f'Running model {id}')\n",
    "        topics, content, correlations = read_data(CFG)\n",
    "        topics, content = get_neighbors(topics, content, CFG)\n",
    "        topics = topics.merge(correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "        pos_score = get_pos_score(topics['content_ids'], topics['predictions'])\n",
    "        print(f'{id} max positive score is {pos_score}')\n",
    "        scores[id] = pos_score\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pd.read_csv(\"/mnt/hdd1/wangjingqi/dataset/lecr/content.csv\")\n",
    "topics = pd.read_csv(\"/mnt/hdd1/wangjingqi/dataset/lecr/topics.csv\")\n",
    "correlations = pd.read_csv(\"/mnt/hdd1/wangjingqi/dataset/lecr/correlations.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>kind</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>copyright_holder</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_00002381196d</td>\n",
       "      <td>Sumar números de varios dígitos: 48,029+233,930</td>\n",
       "      <td>Suma 48,029+233,930 mediante el algoritmo está...</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_000087304a9e</td>\n",
       "      <td>Trovare i fattori di un numero</td>\n",
       "      <td>Sal trova i fattori di 120.\\n\\n</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_0000ad142ddb</td>\n",
       "      <td>Sumar curvas de demanda</td>\n",
       "      <td>Cómo añadir curvas de demanda\\n\\n</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_0000c03adc8d</td>\n",
       "      <td>Nado de aproximação</td>\n",
       "      <td>Neste vídeo você vai aprender o nado de aproxi...</td>\n",
       "      <td>document</td>\n",
       "      <td>\\nNado de aproximação\\nSaber nadar nas ondas ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>Sikana Education</td>\n",
       "      <td>CC BY-NC-ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_00016694ea2a</td>\n",
       "      <td>geometry-m3-topic-a-overview.pdf</td>\n",
       "      <td>geometry-m3-topic-a-overview.pdf</td>\n",
       "      <td>document</td>\n",
       "      <td>Estándares Comunes del Estado de Nueva York\\n\\...</td>\n",
       "      <td>es</td>\n",
       "      <td>Engage NY</td>\n",
       "      <td>CC BY-NC-SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154042</th>\n",
       "      <td>c_fffcbdd4de8b</td>\n",
       "      <td>2. 12: Diffusion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>html5</td>\n",
       "      <td>What will eventually happen to these dyes?\\n\\n...</td>\n",
       "      <td>en</td>\n",
       "      <td>CSU and Merlot</td>\n",
       "      <td>CC BY-NC-SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154043</th>\n",
       "      <td>c_fffe15a2d069</td>\n",
       "      <td>Sommare facendo gruppi da 10</td>\n",
       "      <td>Sal somma 5+68 spezzando il 5 in un 2 e un 3.\\n\\n</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154044</th>\n",
       "      <td>c_fffed7b0d13a</td>\n",
       "      <td>Introdução à subtração</td>\n",
       "      <td>Sal fala sobre o que significa subtrair. Os ex...</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154045</th>\n",
       "      <td>c_ffff04ba7ac7</td>\n",
       "      <td>SA of a Cone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154046</th>\n",
       "      <td>c_ffffe5254266</td>\n",
       "      <td>The Jats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154047 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                             title  \\\n",
       "0       c_00002381196d  Sumar números de varios dígitos: 48,029+233,930    \n",
       "1       c_000087304a9e                    Trovare i fattori di un numero   \n",
       "2       c_0000ad142ddb                           Sumar curvas de demanda   \n",
       "3       c_0000c03adc8d                               Nado de aproximação   \n",
       "4       c_00016694ea2a                  geometry-m3-topic-a-overview.pdf   \n",
       "...                ...                                               ...   \n",
       "154042  c_fffcbdd4de8b                                  2. 12: Diffusion   \n",
       "154043  c_fffe15a2d069                      Sommare facendo gruppi da 10   \n",
       "154044  c_fffed7b0d13a                            Introdução à subtração   \n",
       "154045  c_ffff04ba7ac7                                      SA of a Cone   \n",
       "154046  c_ffffe5254266                                          The Jats   \n",
       "\n",
       "                                              description      kind  \\\n",
       "0       Suma 48,029+233,930 mediante el algoritmo está...     video   \n",
       "1                         Sal trova i fattori di 120.\\n\\n     video   \n",
       "2                       Cómo añadir curvas de demanda\\n\\n     video   \n",
       "3       Neste vídeo você vai aprender o nado de aproxi...  document   \n",
       "4                        geometry-m3-topic-a-overview.pdf  document   \n",
       "...                                                   ...       ...   \n",
       "154042                                                NaN     html5   \n",
       "154043  Sal somma 5+68 spezzando il 5 in un 2 e un 3.\\n\\n     video   \n",
       "154044  Sal fala sobre o que significa subtrair. Os ex...     video   \n",
       "154045                                                NaN     video   \n",
       "154046                                                NaN     video   \n",
       "\n",
       "                                                     text language  \\\n",
       "0                                                     NaN       es   \n",
       "1                                                     NaN       it   \n",
       "2                                                     NaN       es   \n",
       "3       \\nNado de aproximação\\nSaber nadar nas ondas ...       pt   \n",
       "4       Estándares Comunes del Estado de Nueva York\\n\\...       es   \n",
       "...                                                   ...      ...   \n",
       "154042  What will eventually happen to these dyes?\\n\\n...       en   \n",
       "154043                                                NaN       it   \n",
       "154044                                                NaN       pt   \n",
       "154045                                                NaN       en   \n",
       "154046                                                NaN       en   \n",
       "\n",
       "        copyright_holder      license  \n",
       "0                    NaN          NaN  \n",
       "1                    NaN          NaN  \n",
       "2                    NaN          NaN  \n",
       "3       Sikana Education  CC BY-NC-ND  \n",
       "4              Engage NY  CC BY-NC-SA  \n",
       "...                  ...          ...  \n",
       "154042    CSU and Merlot  CC BY-NC-SA  \n",
       "154043               NaN          NaN  \n",
       "154044               NaN          NaN  \n",
       "154045               NaN          NaN  \n",
       "154046               NaN          NaN  \n",
       "\n",
       "[154047 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    nw = 4\n",
    "    bs = 32\n",
    "    top_n = 50\n",
    "    seed = 42\n",
    "    device = 7\n",
    "    max_len = 32\n",
    "    uns_key = \"TiDeTe\"\n",
    "    sup_key = \"TiDeTe\"\n",
    "    model_name = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\"/mnt/hdd1/wangjingqi/ck/lecr/ft/pmmb2_TiDeTe/65610\"]\n",
    "# test(CFG,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, content, correlations = read_data(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, content = get_neighbors(topics, content, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics.merge(correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = get_pos_score(topics['content_ids'], topics['predictions'])\n",
    "print(f'Our max positive score is {pos_score}')#(0.92822,0.84639,0.92973,0.84837)(,0.87946)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.set_index('id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc.collect()\n",
    "# Set id as index for content\n",
    "\n",
    "# Build training set\n",
    "train = build_training_set(topics, content, CFG)\n",
    "print(f'Our training set has {len(train)} rows')\n",
    "# Save train set to disk to train on another notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.to_csv(f'/mnt/hdd1/wangjingqi/dataset/lecr/train_{CFG.max_len}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fe4e0406d3ad7106b208933fab2b0f2ca15cbb9618f84ec8133c53d1894d1ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
